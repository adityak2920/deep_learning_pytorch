{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning of CNN through different layers\n",
    "![Different layers of CNN](img/cnn_layers.png)\n",
    "\n",
    "        The above pictures are of feature maps generated from different layers of VGG16(Visual Geometry Group of Oxford) trained on imagenet.\n",
    "        The Layer 1 generates mostly horizontal, vetical and diagonal lines. There mostly used for detecting edges in an image. The Layer 2 will try to give more informations than first. It detects the corners. The CNN learns to do this on its own. There is no special instruction for the CNN to focus on more complex objects in deeper layers. That’s just how it normally works out when you feed training data into a CNN. Layer 3 is where we start to see some complex patterns like the eyes, face etc. We can assume that this feature maps are obtained from a model trained for detection of human faces. In Layer 4 we see our features finding patterns in the more complex parts of the faces such as eyes.\n",
    "![5th layer of VGG16](img/layer5.png)\n",
    "        \n",
    "        In Layer 5, you can the feature map generates the specific faces of humans, tyres of cars, faces of animals etc. This feature map contains to most information about the patters found in the images.\n",
    "        \n",
    "### Different Parts of a CNN\n",
    "![Different Parts of CNN](img/cnn_parts.png)\n",
    "\n",
    "    Now, we have learnt a lot about CNNs, it's time to implement it using PyTorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of a CNN Classification Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('data/mnist.csv').values\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 1, 28, 28) (8000,)\n",
      "(1500, 1, 28, 28) (1500,)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping our data according to our CNN\n",
    "xtrain=ds[2000:10000, 1:].reshape((-1, 1, 28, 28))/255.0\n",
    "ytrain=ds[2000:10000, 0]\n",
    "\n",
    "xtest=ds[23000:24500, 1:].reshape((-1, 1, 28, 28))/255.0\n",
    "ytest=ds[23000:24500, 0]\n",
    "\n",
    "print(xtrain.shape, ytrain.shape)\n",
    "print(xtest.shape, ytest.shape) # batch_size, no_of_channels, width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Here a question comes, why we divided image by 255 or why it's necessary?\n",
    "Ans:-\n",
    "\n",
    "         These are all scaling techniques, the pixel values are small (Note that these small values still represents the original image), and hence the computation required and time to converge the model reduces significantly. CNN will converge despite taking 0–255 as inputs instead of scaled down to 0 -1 . However, it will converge very slowly.\n",
    "## Data Normalization\n",
    "        Data normalization is an important step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the network. Data normalization is done by subtracting the mean from each pixel and then dividing the result by the standard deviation. The distribution of such data would resemble a Gaussian curve centered at zero. For image inputs we need the pixel numbers to be positive, so we might choose to scale the normalized data in the range [0,1] or [0, 255].\n",
    "        In PyTorch Normalisation is done, channel-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transforms.Normalize??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "# Checking Output Values or labels\n",
    "print(set(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1= nn.Sequential(\n",
    "                nn.Conv2d(1, 16, 5, 1, 2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2))\n",
    "        \n",
    "        self.conv2=nn.Sequential(\n",
    "                nn.Conv2d(16, 32, 5, 1, 2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2))\n",
    "        \n",
    "        self.out=nn.Linear(32*7*7, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=x.view(x.size(0), -1)\n",
    "        \n",
    "        output=F.softmax(self.out(x))\n",
    "#         print(output.size())\n",
    "        return output\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
