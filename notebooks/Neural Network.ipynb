{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A typical training procedure for a neural network is as follows:\n",
    "\n",
    "        - Define the neural network that has some learnable parameters (or weights)\n",
    "        - Iterate over a dataset of inputs\n",
    "        - Process input through the network\n",
    "        - Compute the loss (how far is the output from being correct)\n",
    "        - Propagate gradients back into the networkâ€™s parameters\n",
    "        - Update the weights of the network, typically using a simple update rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Neural Network\n",
    "![Neural Network](img/Perceptron.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls src=\"img/Neural.webm\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (9): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net =   nn.Sequential(\n",
    "        nn.Linear(40, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 4),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4, 1),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "        weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(40, 40)\n",
    "y = torch.randn(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40])\n",
      "tensor(1.5216, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5215, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5214, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5213, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5212, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5212, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5211, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5210, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5209, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5208, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5208, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5207, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5206, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5205, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5204, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5204, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5203, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5202, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5201, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5200, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5199, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5199, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5198, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5197, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5196, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5195, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5195, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5194, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5193, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5192, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5191, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5191, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5190, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5189, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5188, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5187, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5187, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5186, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5185, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5184, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5183, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5183, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5182, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5181, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5180, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5179, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5179, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5178, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5177, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5176, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5175, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5175, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5174, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5173, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5172, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5171, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5171, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5170, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5169, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5168, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5167, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5167, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5166, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5165, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5164, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5164, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5163, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5162, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5161, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5160, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5160, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5159, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5158, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5157, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5156, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5156, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5155, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5154, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5153, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5152, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5152, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5151, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5150, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5149, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5149, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5148, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5147, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5146, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5145, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5145, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5144, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5143, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5142, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5141, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5141, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5140, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5139, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5138, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5138, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.5137, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for t in range(100):\n",
    "    out = net(x)                 # input x and predict based on x\n",
    "    print(y.size())\n",
    "    loss = loss_fn(out, y)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
